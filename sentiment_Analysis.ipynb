{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f444048",
   "metadata": {},
   "source": [
    "# ‘sentiment_Analysis’ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3655d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "06e1ebf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I_Am_Kenzi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PeacefulQuest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PussssyCroook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MattFromTexas31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sharonDay5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 candidate  candidate_confidence relevant_yn  \\\n",
       "id                                                             \n",
       "1   No candidate mentioned                   1.0         yes   \n",
       "2             Scott Walker                   1.0         yes   \n",
       "3   No candidate mentioned                   1.0         yes   \n",
       "4   No candidate mentioned                   1.0         yes   \n",
       "5             Donald Trump                   1.0         yes   \n",
       "\n",
       "    relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "id                                                                              \n",
       "1                      1.0   Neutral                0.6578  None of the above   \n",
       "2                      1.0  Positive                0.6333  None of the above   \n",
       "3                      1.0   Neutral                0.6629  None of the above   \n",
       "4                      1.0  Positive                1.0000  None of the above   \n",
       "5                      1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "    subject_matter_confidence candidate_gold             name  \\\n",
       "id                                                              \n",
       "1                      1.0000            NaN       I_Am_Kenzi   \n",
       "2                      1.0000            NaN    PeacefulQuest   \n",
       "3                      0.6629            NaN    PussssyCroook   \n",
       "4                      0.7039            NaN  MattFromTexas31   \n",
       "5                      1.0000            NaN       sharonDay5   \n",
       "\n",
       "   relevant_yn_gold  retweet_count sentiment_gold subject_matter_gold  \\\n",
       "id                                                                      \n",
       "1               NaN              5            NaN                 NaN   \n",
       "2               NaN             26            NaN                 NaN   \n",
       "3               NaN             27            NaN                 NaN   \n",
       "4               NaN            138            NaN                 NaN   \n",
       "5               NaN            156            NaN                 NaN   \n",
       "\n",
       "                                                 text tweet_coord  \\\n",
       "id                                                                  \n",
       "1   RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "2   RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "3   RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "4   RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "5   RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "                tweet_created            tweet_id tweet_location  \\\n",
       "id                                                                 \n",
       "1   2015-08-07 09:54:46 -0700  629697200650592256            NaN   \n",
       "2   2015-08-07 09:54:46 -0700  629697199560069120            NaN   \n",
       "3   2015-08-07 09:54:46 -0700  629697199312482304            NaN   \n",
       "4   2015-08-07 09:54:45 -0700  629697197118861312          Texas   \n",
       "5   2015-08-07 09:54:45 -0700  629697196967903232            NaN   \n",
       "\n",
       "                 user_timezone  \n",
       "id                              \n",
       "1                        Quito  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4   Central Time (US & Canada)  \n",
       "5                      Arizona  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data= pd.read_csv(r'Sentiment.csv',header=0,index_col=0)\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1c203f70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13871 entries, 1 to 13871\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   candidate                  13775 non-null  object \n",
      " 1   candidate_confidence       13871 non-null  float64\n",
      " 2   relevant_yn                13871 non-null  object \n",
      " 3   relevant_yn_confidence     13871 non-null  float64\n",
      " 4   sentiment                  13871 non-null  object \n",
      " 5   sentiment_confidence       13871 non-null  float64\n",
      " 6   subject_matter             13545 non-null  object \n",
      " 7   subject_matter_confidence  13871 non-null  float64\n",
      " 8   candidate_gold             28 non-null     object \n",
      " 9   name                       13871 non-null  object \n",
      " 10  relevant_yn_gold           32 non-null     object \n",
      " 11  retweet_count              13871 non-null  int64  \n",
      " 12  sentiment_gold             15 non-null     object \n",
      " 13  subject_matter_gold        18 non-null     object \n",
      " 14  text                       13871 non-null  object \n",
      " 15  tweet_coord                21 non-null     object \n",
      " 16  tweet_created              13871 non-null  object \n",
      " 17  tweet_id                   13871 non-null  int64  \n",
      " 18  tweet_location             9959 non-null   object \n",
      " 19  user_timezone              9468 non-null   object \n",
      "dtypes: float64(4), int64(2), object(14)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "sentiment_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "86d111bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13871.000000</td>\n",
       "      <td>13871.000000</td>\n",
       "      <td>13871.000000</td>\n",
       "      <td>13871.000000</td>\n",
       "      <td>13871.000000</td>\n",
       "      <td>1.387100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.855689</td>\n",
       "      <td>0.927304</td>\n",
       "      <td>0.756936</td>\n",
       "      <td>0.782801</td>\n",
       "      <td>45.803331</td>\n",
       "      <td>6.296058e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.241388</td>\n",
       "      <td>0.141696</td>\n",
       "      <td>0.217682</td>\n",
       "      <td>0.258215</td>\n",
       "      <td>153.981724</td>\n",
       "      <td>9.611863e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.294531e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.674200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651700</td>\n",
       "      <td>0.641300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.294861e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.296726e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>6.296882e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4965.000000</td>\n",
       "      <td>6.297017e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       candidate_confidence  relevant_yn_confidence  sentiment_confidence  \\\n",
       "count          13871.000000            13871.000000          13871.000000   \n",
       "mean               0.855689                0.927304              0.756936   \n",
       "std                0.241388                0.141696              0.217682   \n",
       "min                0.222200                0.333300              0.186000   \n",
       "25%                0.674200                1.000000              0.651700   \n",
       "50%                1.000000                1.000000              0.681300   \n",
       "75%                1.000000                1.000000              1.000000   \n",
       "max                1.000000                1.000000              1.000000   \n",
       "\n",
       "       subject_matter_confidence  retweet_count      tweet_id  \n",
       "count               13871.000000   13871.000000  1.387100e+04  \n",
       "mean                    0.782801      45.803331  6.296058e+17  \n",
       "std                     0.258215     153.981724  9.611863e+13  \n",
       "min                     0.222200       0.000000  6.294531e+17  \n",
       "25%                     0.641300       0.000000  6.294861e+17  \n",
       "50%                     1.000000       2.000000  6.296726e+17  \n",
       "75%                     1.000000      44.000000  6.296882e+17  \n",
       "max                     1.000000    4965.000000  6.297017e+17  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "908cbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 20)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f2d9923f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate                       96\n",
       "candidate_confidence             0\n",
       "relevant_yn                      0\n",
       "relevant_yn_confidence           0\n",
       "sentiment                        0\n",
       "sentiment_confidence             0\n",
       "subject_matter                 326\n",
       "subject_matter_confidence        0\n",
       "candidate_gold               13843\n",
       "name                             0\n",
       "relevant_yn_gold             13839\n",
       "retweet_count                    0\n",
       "sentiment_gold               13856\n",
       "subject_matter_gold          13853\n",
       "text                             0\n",
       "tweet_coord                  13850\n",
       "tweet_created                    0\n",
       "tweet_id                         0\n",
       "tweet_location                3912\n",
       "user_timezone                 4403\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "db4938fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1    RT @NancyLeeGrahn: How did everyone feel about...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.text.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24dcc87",
   "metadata": {},
   "source": [
    "## take only text and sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "284cddc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>RT @cappy_yarbrough: Love to see men who will ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>RT @georgehenryw: Who thought Huckabee exceede...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>RT @Lrihendry: #TedCruz As President, I will a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870</th>\n",
       "      <td>RT @JRehling: #GOPDebate Donald Trump says tha...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13871</th>\n",
       "      <td>RT @Lrihendry: #TedCruz headed into the Presid...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13871 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "id                                                                \n",
       "1      RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "2      RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "3      RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "4      RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "5      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "...                                                  ...       ...\n",
       "13867  RT @cappy_yarbrough: Love to see men who will ...  Negative\n",
       "13868  RT @georgehenryw: Who thought Huckabee exceede...  Positive\n",
       "13869  RT @Lrihendry: #TedCruz As President, I will a...  Positive\n",
       "13870  RT @JRehling: #GOPDebate Donald Trump says tha...  Negative\n",
       "13871  RT @Lrihendry: #TedCruz headed into the Presid...  Positive\n",
       "\n",
       "[13871 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data=sentiment_data[['text','sentiment']]\n",
    "sentiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "33abf660",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = sentiment_data[sentiment_data['sentiment'] != 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8fbac1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment\n",
       "id                                                             \n",
       "2   RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "4   RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "5   RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "6   RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
       "7   RT @warriorwoman91: I liked her and was happy ...  Negative"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "727baf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.sentiment.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95adfd4d",
   "metadata": {},
   "source": [
    "# Print the total number of positive and negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06042139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    8493\n",
       "Positive    2236\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da1b411",
   "metadata": {},
   "source": [
    "### Total number of positive sentiments = 2236\n",
    "\n",
    "### Total number of positive sentiments = 8493"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc7f73",
   "metadata": {},
   "source": [
    "# Build a sequential RNN model to predict positive and negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f85eabd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords   # to get collection of stopwords\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b17fa01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8aafe52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "095570d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = new_data['text']       # Reviews/Input\n",
    "y_data = new_data['sentiment']    # Sentiment/Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e097e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-PROCESS REVIEW\n",
    "x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd0013ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE SENTIMENT -> 0 & 1\n",
    "y_data = y_data.replace('positive', 1)\n",
    "y_data = y_data.replace('negative', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "574278e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "id\n",
      "2        [rt, scottwalker, didn, catch, full, gopdebate...\n",
      "4        [rt, robgeorge, that, carly, fiorina, trending...\n",
      "5        [rt, danscavino, gopdebate, w, realdonaldtrump...\n",
      "6        [rt, gregabbott, tx, tedcruz, on, first, day, ...\n",
      "7        [rt, warriorwoman, i, liked, happy, i, heard, ...\n",
      "                               ...                        \n",
      "13867    [rt, cappy, yarbrough, love, see, men, never, ...\n",
      "13868    [rt, georgehenryw, who, thought, huckabee, exc...\n",
      "13869    [rt, lrihendry, tedcruz, as, president, i, alw...\n",
      "13870    [rt, jrehling, gopdebate, donald, trump, says,...\n",
      "13871    [rt, lrihendry, tedcruz, headed, presidential,...\n",
      "Name: text, Length: 10729, dtype: object \n",
      "\n",
      "Sentiment\n",
      "id\n",
      "2        Positive\n",
      "4        Positive\n",
      "5        Positive\n",
      "6        Positive\n",
      "7        Negative\n",
      "           ...   \n",
      "13867    Negative\n",
      "13868    Positive\n",
      "13869    Positive\n",
      "13870    Negative\n",
      "13871    Positive\n",
      "Name: sentiment, Length: 10729, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('text')\n",
    "print(x_data, '\\n')\n",
    "print('Sentiment')\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdcab75",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4fffdd29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "id\n",
      "6346              [gopdebate, ahem, http, co, hd, ukbursz]\n",
      "7093     [realdonaldtrump, whine, whine, whine, boo, ho...\n",
      "4711     [i, not, of, those, conservatives, who, suppor...\n",
      "2920     [gopdebate, maybe, right, try, amp, destroy, o...\n",
      "12550    [rt, ericstonestreet, trump, cam, hands, gopde...\n",
      "                               ...                        \n",
      "2698     [rt, steveamiri, how, is, jeff, dunham, workin...\n",
      "4133     [rt, amymek, thank, tedcruz, calling, rhino, g...\n",
      "1062     [rt, deborahpeasley, multiple, shots, scott, w...\n",
      "8429     [rt, larryelder, trump, said, megyn, ask, nine...\n",
      "11642             [rand, paul, vote, gopdebates, randpaul]\n",
      "Name: text, Length: 8583, dtype: object \n",
      "\n",
      "id\n",
      "6825     [topics, left, gopdebate, on, th, anniversary,...\n",
      "9815     [rt, wilberforce, one, favorite, things, gopde...\n",
      "12939    [trump, hand, gestures, second, season, one, p...\n",
      "11655    [rt, rwsurfergirl, ask, trump, legitimate, que...\n",
      "5339     [good, luck, everyone, competing, gopdebate, b...\n",
      "                               ...                        \n",
      "1813     [how, earn, jeb, http, co, jkgx, ojrwi, gopdeb...\n",
      "6673     [rt, aelmore, i, tried, watch, debate, instead...\n",
      "2084     [rt, pjhughes, foxnews, debate, moderators, un...\n",
      "9935     [rt, monaeltahawy, paging, donald, beat, jamai...\n",
      "5017     [foxnewspolitics, gopdebate, megankelly, clear...\n",
      "Name: text, Length: 2146, dtype: object \n",
      "\n",
      "Test Set\n",
      "id\n",
      "6346     Negative\n",
      "7093     Negative\n",
      "4711     Negative\n",
      "2920     Negative\n",
      "12550    Negative\n",
      "           ...   \n",
      "2698     Negative\n",
      "4133     Positive\n",
      "1062     Positive\n",
      "8429     Positive\n",
      "11642    Positive\n",
      "Name: sentiment, Length: 8583, dtype: object \n",
      "\n",
      "id\n",
      "6825     Negative\n",
      "9815     Positive\n",
      "12939    Negative\n",
      "11655    Negative\n",
      "5339     Positive\n",
      "           ...   \n",
      "1813     Negative\n",
      "6673     Negative\n",
      "2084     Negative\n",
      "9935     Negative\n",
      "5017     Negative\n",
      "Name: sentiment, Length: 2146, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "68833368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    text_length = []\n",
    "    for text in x_train:\n",
    "        text_length.append(len(text))\n",
    "    text_length = np.array(text_length)\n",
    "    text_length = text_length[~np.isnan(text_length)]  # Exclude NaN values\n",
    "    return int(np.ceil(np.mean(text_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "62373157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[    1  5484     6 ...     0     0     0]\n",
      " [   10  1775  1775 ...     1     0     0]\n",
      " [    4    71   417 ...    59    42    11]\n",
      " ...\n",
      " [    2 13424  1589 ...    28   106  1834]\n",
      " [    2   421     8 ...   249     4   196]\n",
      " [  156   127   144 ...     0     0     0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[1016  598    1 ...  159  595  764]\n",
      " [   2  887   28 ...  293  123  888]\n",
      " [   8  870  703 ...    0    0    0]\n",
      " ...\n",
      " [   2   22   14 ...  856   73    0]\n",
      " [   2  101 1798 ...    0    0    0]\n",
      " [2399    1 1497 ...   11   64    0]] \n",
      "\n",
      "Maximum review length:  13\n"
     ]
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "04ec4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding dimension\n",
    "embedding_dim = 100\n",
    "num_classes = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33e7f9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 13, 100)           1342500   \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 128)               29312     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,372,070\n",
      "Trainable params: 1,372,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an Embedding layer\n",
    "model.add(Embedding(input_dim=total_words, output_dim=embedding_dim, input_length=max_length))\n",
    "\n",
    "# Add a SimpleRNN layer\n",
    "model.add(SimpleRNN(units=128))\n",
    "\n",
    "# Add a Dense layer for classification\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4176871f",
   "metadata": {},
   "source": [
    "Training\n",
    "For training, it is simple. We only need to fit our x_train (input) and y_train (output/label) data. For this training, I use a mini-batch learning method with a batch_size of 128 and 5 epochs.\n",
    "\n",
    "Also, I added a callback called checkpoint to save the model locally for every epoch if its accuracy improved from the previous epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d6f6243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/RNN',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ed4f762a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "269/269 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.8284\n",
      "Epoch 1: accuracy improved from -inf to 0.82838, saving model to models\\RNN\n",
      "INFO:tensorflow:Assets written to: models\\RNN\\assets\n",
      "269/269 [==============================] - 14s 45ms/step - loss: 0.4062 - accuracy: 0.8284\n",
      "Epoch 2/5\n",
      "268/269 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9257\n",
      "Epoch 2: accuracy improved from 0.82838 to 0.92567, saving model to models\\RNN\n",
      "INFO:tensorflow:Assets written to: models\\RNN\\assets\n",
      "269/269 [==============================] - 13s 49ms/step - loss: 0.1992 - accuracy: 0.9257\n",
      "Epoch 3/5\n",
      "267/269 [============================>.] - ETA: 0s - loss: 0.1078 - accuracy: 0.9635\n",
      "Epoch 3: accuracy improved from 0.92567 to 0.96318, saving model to models\\RNN\n",
      "INFO:tensorflow:Assets written to: models\\RNN\\assets\n",
      "269/269 [==============================] - 12s 45ms/step - loss: 0.1081 - accuracy: 0.9632\n",
      "Epoch 4/5\n",
      "268/269 [============================>.] - ETA: 0s - loss: 0.0879 - accuracy: 0.9719\n",
      "Epoch 4: accuracy improved from 0.96318 to 0.97169, saving model to models\\RNN\n",
      "INFO:tensorflow:Assets written to: models\\RNN\\assets\n",
      "269/269 [==============================] - 12s 46ms/step - loss: 0.0881 - accuracy: 0.9717\n",
      "Epoch 5/5\n",
      "269/269 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9726\n",
      "Epoch 5: accuracy improved from 0.97169 to 0.97262, saving model to models\\RNN\n",
      "INFO:tensorflow:Assets written to: models\\RNN\\assets\n",
      "269/269 [==============================] - 13s 47ms/step - loss: 0.0751 - accuracy: 0.9726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ec85dafe0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert string labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert the target data to one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train_encoded)\n",
    "y_test_one_hot = to_categorical(y_test_encoded)\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=embedding_dim, input_length=max_length))\n",
    "model.add(SimpleRNN(units=128))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train_one_hot, epochs=5, batch_size=32 ,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "67abb291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 6ms/step - loss: 0.4207 - accuracy: 0.8509\n",
      "Test Loss: 0.42068415880203247\n",
      "Test Accuracy: 0.8508853912353516\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test_one_hot)\n",
    "\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d27ee7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 5ms/step\n",
      "Correct Prediction: 1826\n",
      "Wrong Prediction: 320\n",
      "Accuracy: 85.08853681267475\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(x_test)>0.5).astype(\"int32\")\n",
    "\n",
    "true = 0\n",
    "for i, y in enumerate(y_test_one_hot):\n",
    "    if np.array_equal(y, y_pred[i]):\n",
    "        true += 1\n",
    "        \n",
    "print('Correct Prediction: {}'.format(true))\n",
    "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
    "print('Accuracy: {}'.format(true/len(y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2282f76c",
   "metadata": {},
   "source": [
    "### Load Saved Model\n",
    "##### Load saved model and use it to predict a movie review statement's sentiment (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "06e3f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('models/RNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec4653",
   "metadata": {},
   "source": [
    "## Based on the model, check the sentiment for the following two sentences\n",
    "#### a. 'He is a great leader.'\n",
    "#### b. 'He is a terrible leader.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1239f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50  60  97 267   0   0   0   0   0   0   0   0   0]\n",
      " [ 50  60 901 267   0   0   0   0   0   0   0   0   0]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Sentence: He is a great leader.\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Sentence: He is a terrible leader.\n",
      "Predicted Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the sentences\n",
    "sentences = ['He is a great leader.', 'He is a terrible leader.']\n",
    "sequences = token.texts_to_sequences(sentences)\n",
    "tokenize_words = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "print(tokenize_words)\n",
    "\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = loaded_model.predict(tokenize_words)\n",
    "\n",
    "# Get the predicted sentiment labels\n",
    "sentiments = [ 'Negative','Positive']\n",
    "predicted_labels = [sentiments[np.argmax(pred)] for pred in predictions]\n",
    "\n",
    "# Print the predicted sentiment for each sentence\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(\"Sentence: {}\".format(sentence))\n",
    "    print(\"Predicted Sentiment: {}\".format(predicted_labels[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e804c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066b2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91307af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
